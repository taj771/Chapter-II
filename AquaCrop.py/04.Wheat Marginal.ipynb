{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import psutil\n",
    "print(psutil.virtual_memory())\n",
    "!pip install git+https://github.com/aquacropos/aquacrop\n",
    "import os\n",
    "os.environ['DEVELOPMENT'] = 'True'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the downloaded Daymet data\n",
    "climate_data = pd.read_csv('/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/ClimateData/weather_data_Aqua.csv', on_bad_lines='skip')\n",
    "\n",
    "# Check if 'Date' column exists\n",
    "if 'Date' in climate_data.columns:\n",
    "    # Convert 'Date' column to datetime\n",
    "    climate_data['Date'] = pd.to_datetime(climate_data['Date'], errors='coerce')\n",
    "\n",
    "    # Remove rows with missing Date values\n",
    "    climate_data = climate_data.dropna(subset=['Date'])\n",
    "\n",
    "    # Extract Day, Month, and Year from the Date column\n",
    "    climate_data['Day'] = climate_data['Date'].dt.day\n",
    "    climate_data['Month'] = climate_data['Date'].dt.month\n",
    "    climate_data['Year'] = climate_data['Date'].dt.year\n",
    "    e_a = climate_data['e_a']  # actual vapor pressure (kpa)\n",
    "\n",
    "    # Calculate necessary climate variables\n",
    "    T_max = climate_data['MaxTemp']  # Maximum temperature (°C)\n",
    "    T_min = climate_data['MinTemp']  # Minimum temperature (°C)\n",
    "    precipitation = climate_data['Precipitation']  # Precipitation (mm)\n",
    "    solar_radiation = climate_data['R_n']  # Solar radiation (MJ/m²/day)\n",
    "\n",
    "    # Calculate mean temperature\n",
    "    T_mean = (T_max + T_min) / 2\n",
    "\n",
    "    # Calculate saturation vapor pressure (e_s) in kPa\n",
    "    e_s = 0.6108 * np.exp((17.27 * T_mean) / (T_mean + 237.3))\n",
    "\n",
    "    # Assuming relative humidity (RH) is available or use an average value\n",
    "    #RH = 62  # Example average RH of 50%\n",
    "    #e_a = (RH / 100) * e_s  # Actual vapor pressure in kPa\n",
    "\n",
    "    # Define other constants\n",
    "    R_n = solar_radiation  # Net radiation (MJ/m²/day)\n",
    "    G = 0  # Soil heat flux density (MJ/m²/day), often negligible\n",
    "    gamma = 0.066  # Psychrometric constant (kPa/°C)\n",
    "    u = 2  # Average wind speed in m/s (if available, else use an estimated value)\n",
    "\n",
    "    # Calculate slope of the saturation vapor pressure curve (Δ)\n",
    "    delta = (4098 * e_s) / ((T_mean + 237.3) ** 2)\n",
    "\n",
    "    # Calculate reference ET (ET₀) using the Penman-Monteith equation\n",
    "    ReferenceET = (0.408 * delta * (R_n - G) + gamma * (900 / (T_mean + 273)) * u * (e_s - e_a)) / (delta + gamma * (1 + 0.34 * u))\n",
    "\n",
    "    # Add ET₀ to the DataFrame\n",
    "    climate_data['ReferenceET'] = ReferenceET\n",
    "\n",
    "    # Reorder the columns to bring Day, Month, Year first\n",
    "    climate_data = climate_data[['Day', 'Month', 'Year'] + [col for col in climate_data.columns if col not in ['Day', 'Month', 'Year']]]\n",
    "\n",
    "    # Save the DataFrame to a text file (CSV format)\n",
    "    climate_data.to_csv('daymet_data_with_et0.csv', index=False)  # Save as a tab-separated text file\n",
    "\n",
    "    print(\"Reference ET₀ calculated and saved to 'daymet_data_with_et0.csv'.\")\n",
    "else:\n",
    "    print(\"The 'Date' column does not exist in the dataset.\")"
   ],
   "id": "f8d76d250910f186",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"daymet_data_with_et0.csv\")\n",
    "\n",
    "# Get a list of unique sites\n",
    "unique_sites = df['site'].unique()\n",
    "\n",
    "# Specify the directories where the weather files will be saved\n",
    "weather_dir = \"./ClimateData\"\n",
    "os.makedirs(weather_dir, exist_ok=True)\n",
    "\n",
    "# Define the columns to select and rename\n",
    "columns_to_select = ['Day', 'Month', 'Year', 'MinTemp', 'MaxTemp', 'Precipitation', 'ReferenceET']\n",
    "columns_to_rename = {\n",
    "    'MinTemp': 'Tmin(c)',\n",
    "    'MaxTemp': 'Tmax(c)',\n",
    "    'Precipitation': 'Prcp(mm)',\n",
    "    'ReferenceET': 'Et0(mm)'\n",
    "}\n",
    "\n",
    "# Loop through each unique site and save its weather data to a text file\n",
    "for site in unique_sites:\n",
    "    df_filtered = df[df['site'] == site][columns_to_select].rename(columns=columns_to_rename)\n",
    "\n",
    "    # Create a filename for the current site's weather data\n",
    "    weather_filename = os.path.join(weather_dir, f\"site_{site}.txt\")\n",
    "\n",
    "    # Save the filtered data to the weather file\n",
    "    df_filtered.to_csv(weather_filename, sep='\\t', index=False)\n",
    "    print(f\"Weather data saved for site {site}.\")\n"
   ],
   "id": "bfe33fa51da3aea4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from aquacrop.utils.prepare_weather import prepare_weather\n",
    "\n",
    "# Define the directory containing the weather files\n",
    "input_dir = \"./ClimateData\"\n",
    "prepared_wdf_dir = \"./PreparedWDF\"  # Directory to save prepared wdf\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "os.makedirs(prepared_wdf_dir, exist_ok=True)\n",
    "\n",
    "# Number of sites\n",
    "num_sites = 397  # Adjust as necessary\n",
    "\n",
    "# Create a list of climate file names dynamically\n",
    "climate_files = [f\"site_{i}.txt\" for i in range(1, num_sites + 1)]  # e.g., site_1.txt, site_2.txt, etc.\n",
    "\n",
    "# Loop through each file name\n",
    "for climate_file in climate_files:\n",
    "    file_path = os.path.join(input_dir, climate_file)  # Construct the full file path\n",
    "\n",
    "    if os.path.exists(file_path):  # Check if the file exists\n",
    "        try:\n",
    "            # Prepare weather data\n",
    "            wdf = prepare_weather(file_path)  \n",
    "\n",
    "            # Save the prepared weather data to CSV\n",
    "            prepared_wdf_path = os.path.join(prepared_wdf_dir, f\"prepared_{climate_file}\")\n",
    "            wdf.to_csv(prepared_wdf_path, index=False)  # Assuming wdf can be converted to CSV\n",
    "\n",
    "            print(f\"Weather data prepared and saved for {climate_file}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {climate_file}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n"
   ],
   "id": "2b44ae9fa9a722d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# At this point, wdf_list will contain all the prepared weather data\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aquacrop import AquaCropModel, Soil, Crop, InitialWaterContent, IrrigationManagement\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import fmin  # Ensure fmin is imported for optimization\n",
    "\n",
    "\n",
    "# Prepare the weather data\n",
    "\n",
    "#wdf1 = prepare_weather(\"ClimateData/champion_climate1.txt\")\n",
    "#wdf2 = prepare_weather(\"ClimateData/champion_climate2.txt\")\n",
    "\n",
    "def run_model(smts, max_irr_season, year1, year2, wdf):\n",
    "    \"\"\"\n",
    "    Function to run model and return results for a given set of soil moisture targets.\n",
    "    \"\"\"\n",
    "    wheat = Crop('Wheat',\n",
    "                planting_date='05/01',\n",
    "                harvest_date='10/30',\n",
    "                CropType=3,  # Conservative parameters\n",
    "                Tbase=5,\n",
    "                Tupp=35,\n",
    "                #Maturity=975,\n",
    "                #Emergence=42,\n",
    "                #MaxRooting=597,\n",
    "                #Flowering=114,\n",
    "                #Senescence=821,\n",
    "                #HIstart=224,\n",
    "                Zmax=0.7,\n",
    "                WP=16,\n",
    "                Tmin_up=8,\n",
    "                Tmax_lo=40,\n",
    "                exc=50,\n",
    "                CGC=0.16764,\n",
    "                CCx=0.95,\n",
    "                CDC=0.13653,\n",
    "                #SeedSize=5,\n",
    "                Kcb=1.10,\n",
    "                fshape_r=15,\n",
    "                SxTopQ=0.020,\n",
    "                SxBotQ=0.005,\n",
    "                p_up4=0.8,\n",
    "                p_up2=0.55,\n",
    "                fshape_w1=4,\n",
    "                PlantPop=2000000\n",
    "                )  # Plant population (plants/ha))  # Define crop\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    soil = Soil('LoamySand')  # Define soil\n",
    "    init_wc = InitialWaterContent(wc_type='Pct', value=[70])  # Define initial soil water conditions\n",
    "\n",
    "    irrmngt = IrrigationManagement(irrigation_method=1, SMT=smts, MaxIrrSeason=max_irr_season)  # Define irrigation management\n",
    "\n",
    "    # Create and run model\n",
    "    model = AquaCropModel(f'{year1}/05/01', f'{year2}/10/31', wdf, soil, wheat,\n",
    "                          irrigation_management=irrmngt, initial_water_content=init_wc)\n",
    "\n",
    "    model.run_model(till_termination=True)\n",
    "    return model.get_simulation_results()\n",
    "\n",
    "def evaluate(smts, max_irr_season, wdf, test=False):\n",
    "    \"\"\"\n",
    "    Function to run model and calculate reward (yield) for a given set of soil moisture targets.\n",
    "    \"\"\"\n",
    "    # Run model # year chnage ### year chnage\n",
    "    out = run_model(smts, max_irr_season, year1=2018, year2=2018, wdf=wdf)\n",
    "\n",
    "    # Get yields and total irrigation\n",
    "    yld = out['Fresh yield (tonne/ha)'].mean()\n",
    "    tirr = out['Seasonal irrigation (mm)'].mean()\n",
    "\n",
    "    reward = yld\n",
    "\n",
    "    # Return either the negative reward (for the optimization)\n",
    "    # or the yield and total irrigation (for analysis)\n",
    "    if test:\n",
    "        return yld, tirr, reward\n",
    "    else:\n",
    "        return -reward\n",
    "\n",
    "# Modify get_starting_point to accept wdf\n",
    "def get_starting_point(num_smts, max_irr_season, num_searches, wdf):\n",
    "    \"\"\"\n",
    "    Find good starting threshold(s) for optimization.\n",
    "    \"\"\"\n",
    "    # Get random SMT's\n",
    "    x0list = np.random.rand(num_searches, num_smts) * 100\n",
    "    rlist = []\n",
    "\n",
    "    # Evaluate random SMT's\n",
    "    for xtest in x0list:\n",
    "        r = evaluate(xtest, max_irr_season, wdf)\n",
    "        rlist.append(r)\n",
    "\n",
    "    # Save best SMT\n",
    "    x0 = x0list[np.argmin(rlist)]\n",
    "    return x0\n",
    "\n",
    "# Modify optimize to accept wdf\n",
    "def optimize(num_smts, max_irr_season, wdf, num_searches=100):\n",
    "    \"\"\"\n",
    "    Optimize thresholds to be profit-maximizing.\n",
    "    \"\"\"\n",
    "    # Get starting optimization strategy\n",
    "    x0 = get_starting_point(num_smts, max_irr_season, num_searches, wdf)\n",
    "\n",
    "    # Run optimization\n",
    "    res = fmin(evaluate, x0, disp=0, args=(max_irr_season, wdf))\n",
    "\n",
    "    # Reshape array\n",
    "    smts = res.squeeze()\n",
    "\n",
    "    # Evaluate optimal strategy\n",
    "    return smts\n",
    "\n"
   ],
   "id": "31341e92ab4002af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "max_irr_values = [10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200]",
   "id": "370243b0718ba016",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(1, 20)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_1.csv\", index=False)\n"
   ],
   "id": "42064e268dd75722",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(20, 30)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_2.csv\",\n",
    "    index=False)"
   ],
   "id": "9433287ae9af6e92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(30, 40)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_3.csv\",\n",
    "    index=False)"
   ],
   "id": "2ff8c7abc863f5b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(40, 50)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_4.csv\",\n",
    "    index=False)"
   ],
   "id": "6aa40bec81492c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(50, 60)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_5.csv\",\n",
    "    index=False)"
   ],
   "id": "18ef6d801c8f47a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(60, 70)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_6.csv\",\n",
    "    index=False)\n"
   ],
   "id": "9410a8544f16352c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(70, 80)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_7.csv\",\n",
    "    index=False)\n"
   ],
   "id": "9ba77fc45108effb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(80, 90)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_8.csv\",\n",
    "    index=False)\n"
   ],
   "id": "7482b8c9b67f6045",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(90, 100)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_9.csv\",\n",
    "    index=False)\n"
   ],
   "id": "b5ff3a4e846cae3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(100, 110)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_10.csv\",\n",
    "    index=False)\n"
   ],
   "id": "465b4c795ed57b34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(110, 120)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_11.csv\",\n",
    "    index=False)\n"
   ],
   "id": "a732ace6c3532008",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(120, 130)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_12.csv\",\n",
    "    index=False)\n"
   ],
   "id": "7bfa3287298dd76e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(130, 140)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_13.csv\",\n",
    "    index=False)\n"
   ],
   "id": "1984d15daa0017c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(140, 150)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_14.csv\",\n",
    "    index=False)\n"
   ],
   "id": "49e592ca7ab69571",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(150, 160)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_15.csv\",\n",
    "    index=False)\n"
   ],
   "id": "fa54e012b529373a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(160, 170)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_16.csv\",\n",
    "    index=False)"
   ],
   "id": "cb2322cac2fc8992",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(170, 180)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_17.csv\",\n",
    "    index=False)\n"
   ],
   "id": "b3d6740fd84f2b39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(180, 190)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_18.csv\",\n",
    "    index=False)\n"
   ],
   "id": "53d3de5ea9a35c7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(190, 200)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_19.csv\",\n",
    "    index=False)\n"
   ],
   "id": "c486a626029d67d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(200, 210)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_20.csv\",\n",
    "    index=False)\n"
   ],
   "id": "94feabb7414da579",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(210, 220)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_21.csv\",\n",
    "    index=False)\n"
   ],
   "id": "ddc8cc77e68618fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(220, 230)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_22.csv\",\n",
    "    index=False)\n"
   ],
   "id": "fef0973e8a2563fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(230, 240)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_23.csv\",\n",
    "    index=False)\n"
   ],
   "id": "a52d99c7778f96b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(240, 250)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_24.csv\",\n",
    "    index=False)\n"
   ],
   "id": "422cbcc00b8b81a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(250, 260)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_25.csv\",\n",
    "    index=False)\n"
   ],
   "id": "7d7d6f16a92b66a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(260, 270)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_26.csv\",\n",
    "    index=False)\n"
   ],
   "id": "abd3d6e7fd0f322d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(270, 280)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_27.csv\",\n",
    "    index=False)\n"
   ],
   "id": "b2734d91ff71e0e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(280, 290)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_28.csv\",\n",
    "    index=False)\n"
   ],
   "id": "b315cd98413074f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(290, 300)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_29.csv\",\n",
    "    index=False)\n"
   ],
   "id": "1b76900e1ac3459b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(300, 310)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_30.csv\",\n",
    "    index=False)\n"
   ],
   "id": "e80314b650a80f8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(310, 320)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_31.csv\",\n",
    "    index=False)\n"
   ],
   "id": "b37580b95c40eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(320, 330)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_32.csv\",\n",
    "    index=False)\n"
   ],
   "id": "bb74bc99a111168d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(330, 340)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_33.csv\",\n",
    "    index=False)\n"
   ],
   "id": "5be1e1bd09d583f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(340, 350)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_34.csv\",\n",
    "    index=False)\n"
   ],
   "id": "83f842cc4bdc9a63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(350, 360)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_35.csv\",\n",
    "    index=False)\n"
   ],
   "id": "b0b2b3bd055af307",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(360, 370)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_36.csv\",\n",
    "    index=False)\n"
   ],
   "id": "cfcbf2fc6149a3d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(370, 380)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_37.csv\",\n",
    "    index=False)\n"
   ],
   "id": "661a7cbe631ac56c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(380, 390)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_38.csv\",\n",
    "    index=False)\n"
   ],
   "id": "d32df20a5094e62f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have 300 sites\n",
    "site_ids = range(390, 398)  # Adjust site IDs as needed\n",
    "wdfs = {site_id: prepare_weather(f\"ClimateData/site_{site_id}.txt\") for site_id in\n",
    "        site_ids}  # Prepare wdfs for all sites\n",
    "\n",
    "\n",
    "# Function to process each site and irrigation level\n",
    "def process_site_irr_max(site_id, max_irr, wdf):\n",
    "    smts = optimize(4, max_irr, wdf)  # Replace with your optimization function\n",
    "    yld, tirr, _ = evaluate(smts, max_irr, wdf, True)  # Replace with your evaluation function\n",
    "\n",
    "    return {\n",
    "        'Site_ID': site_id,\n",
    "        'Max_Irrigation_mm': max_irr,\n",
    "        'Optimal_SMTs': smts.tolist(),\n",
    "        'Yield_tonne_per_ha': yld,\n",
    "        'Total_Irrigation_mm': tirr\n",
    "    }\n",
    "\n",
    "\n",
    "# Instead of creating a new list every time, we can use a preallocated list\n",
    "results_list = []\n",
    "\n",
    "# Parallel processing using joblib\n",
    "all_results = Parallel(n_jobs=15)(\n",
    "    delayed(process_site_irr_max)(site_id, max_irr, wdfs[site_id])\n",
    "    for max_irr in max_irr_values\n",
    "    for site_id in site_ids\n",
    ")\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_39.csv\",\n",
    "    index=False)\n"
   ],
   "id": "f9389bd781664852",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "df_1 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_1.csv\")\n",
    "df_2 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_2.csv\")\n",
    "df_3 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_3.csv\")\n",
    "df_4 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_4.csv\")\n",
    "df_5 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_5.csv\")\n",
    "df_6 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_6.csv\")\n",
    "df_7 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_7.csv\")\n",
    "df_8 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_8.csv\")\n",
    "df_9 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_9.csv\")\n",
    "df_10 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_10.csv\")\n",
    "df_11 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_11.csv\")\n",
    "df_12 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_12.csv\")\n",
    "df_13 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_13.csv\")\n",
    "df_14 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_14.csv\")\n",
    "df_15 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_15.csv\")\n",
    "df_16 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_16.csv\")\n",
    "df_17 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_17.csv\")\n",
    "df_18 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_18.csv\")\n",
    "df_19 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_19.csv\")\n",
    "df_20 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_20.csv\")\n",
    "df_21 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_21.csv\")\n",
    "df_22 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_22.csv\")\n",
    "df_23 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_23.csv\")\n",
    "df_24 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_24.csv\")\n",
    "df_25 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_25.csv\")\n",
    "df_26 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_26.csv\")\n",
    "df_27 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_27.csv\")\n",
    "df_28 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_28.csv\")\n",
    "df_29 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_29.csv\")\n",
    "df_30 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_30.csv\")\n",
    "df_31 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_31.csv\")\n",
    "df_32 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_32.csv\")\n",
    "df_33 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_33.csv\")\n",
    "df_34 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_34.csv\")\n",
    "df_35 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_35.csv\")\n",
    "df_36 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_36.csv\")\n",
    "df_37 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_37.csv\")\n",
    "df_38 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_38.csv\")\n",
    "df_39 = pd.read_csv(\n",
    "    \"/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/TempDirectory/merged_results_39.csv\")\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_results = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9,\n",
    "                            df_10, df_11, df_12, df_13, df_14, df_15, df_16, df_17, df_18, df_19,\n",
    "                            df_20, df_21, df_22, df_23, df_24, df_25, df_26, df_27, df_28, df_29,\n",
    "                            df_30, df_31, df_32, df_33, df_34, df_35, df_36, df_37, df_38, df_39], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_results.to_csv(\n",
    "    '/Users/tharakajayalath/Library/CloudStorage/OneDrive-UniversityofSaskatchewan/Chapter II-IrrigationValue/AquaCropOPSyData/WheatMarginal/merged_simulation_results_wheat_marginal_2018_misssing_irrigation.csv',\n",
    "    index=False)\n"
   ],
   "id": "a279e140a791b9ab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
